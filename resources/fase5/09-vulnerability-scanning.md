# M√≥dulo 09: Vulnerability Scanning

## üìã Introducci√≥n

El vulnerability scanning es una pr√°ctica esencial en DevSecOps que permite identificar vulnerabilidades de seguridad en c√≥digo, dependencias, contenedores e infraestructura de manera automatizada. Este m√≥dulo cubre la implementaci√≥n de scanners de vulnerabilidades en pipelines CI/CD y la gesti√≥n continua de riesgos de seguridad.

### ¬øQu√© es Vulnerability Scanning?

Vulnerability scanning es el proceso de:

- **Identificar** vulnerabilidades conocidas en el c√≥digo y dependencias
- **Evaluar** el riesgo y criticidad de las vulnerabilidades
- **Priorizar** la remediaci√≥n basada en el impacto
- **Automatizar** el scanning en pipelines CI/CD
- **Monitorear** continuamente nuevas vulnerabilidades

### Tipos de Vulnerability Scanning

- **SAST (Static Application Security Testing)**: An√°lisis de c√≥digo fuente
- **DAST (Dynamic Application Security Testing)**: An√°lisis de aplicaciones en ejecuci√≥n
- **SCA (Software Composition Analysis)**: An√°lisis de dependencias de terceros
- **Container Scanning**: An√°lisis de im√°genes de contenedores
- **Infrastructure Scanning**: An√°lisis de configuraci√≥n de infraestructura

---

## üéØ Objetivos de Aprendizaje

Al completar este m√≥dulo, ser√°s capaz de:

1. **Implementar** vulnerability scanning en pipelines CI/CD
2. **Configurar** diferentes tipos de scanners (SAST, DAST, SCA)
3. **Integrar** container scanning con registries
4. **Automatizar** la gesti√≥n de vulnerabilidades
5. **Configurar** pol√≠ticas de seguridad automatizadas
6. **Monitorear** vulnerabilidades en tiempo real
7. **Implementar** vulnerability management workflows
8. **Crear** reportes de seguridad automatizados

---

## üèóÔ∏è Arquitectura de Vulnerability Scanning

### 1. Stack de Vulnerability Scanning

```yaml
# docker-compose.vulnerability-scanning.yml
version: '3.8'

services:
  # SonarQube para SAST
  sonarqube:
    image: sonarqube:10.2.1-community
    container_name: vuln-sonarqube
    ports:
      - "9000:9000"
    environment:
      - SONAR_JDBC_URL=jdbc:postgresql://postgres:5432/sonarqube
      - SONAR_JDBC_USERNAME=sonarqube
      - SONAR_JDBC_PASSWORD=sonarqube123
    volumes:
      - sonarqube_data:/opt/sonarqube/data
      - sonarqube_logs:/opt/sonarqube/logs
      - sonarqube_extensions:/opt/sonarqube/extensions
    networks:
      - vuln_network
    depends_on:
      - postgres

  # PostgreSQL para SonarQube
  postgres:
    image: postgres:15
    container_name: vuln-postgres
    environment:
      - POSTGRES_USER=sonarqube
      - POSTGRES_PASSWORD=sonarqube123
      - POSTGRES_DB=sonarqube
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - vuln_network

  # OWASP ZAP para DAST
  zap:
    image: zaproxy/zap-stable:latest
    container_name: vuln-zap
    ports:
      - "8080:8080"
      - "8090:8090"
    command: zap-webswing.sh
    environment:
      - ZAP_PORT=8080
    volumes:
      - zap_data:/zap/wrk
    networks:
      - vuln_network

  # Trivy para container scanning
  trivy:
    image: aquasec/trivy:latest
    container_name: vuln-trivy
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - trivy_cache:/root/.cache/trivy
    networks:
      - vuln_network

  # DefectDojo para vulnerability management
  defectdojo:
    image: defectdojo/defectdojo-django:latest
    container_name: vuln-defectdojo
    ports:
      - "8000:8000"
    environment:
      - DD_DATABASE_URL=postgres://defectdojo:defectdojo@postgres-dd:5432/defectdojo
      - DD_SECRET_KEY=your-secret-key-here
      - DD_DEBUG=True
      - DD_ALLOWED_HOSTS=*
    volumes:
      - defectdojo_media:/app/media
    networks:
      - vuln_network
    depends_on:
      - postgres-dd

  # PostgreSQL para DefectDojo
  postgres-dd:
    image: postgres:15
    container_name: vuln-postgres-dd
    environment:
      - POSTGRES_USER=defectdojo
      - POSTGRES_PASSWORD=defectdojo
      - POSTGRES_DB=defectdojo
    volumes:
      - postgres_dd_data:/var/lib/postgresql/data
    networks:
      - vuln_network

  # Dependency-Track para SCA
  dependency-track:
    image: dependencytrack/apiserver:latest
    container_name: vuln-dependency-track-api
    ports:
      - "8081:8080"
    environment:
      - ALPINE_DATABASE_MODE=external
      - ALPINE_DATABASE_URL=jdbc:postgresql://postgres-dt:5432/dependencytrack
      - ALPINE_DATABASE_DRIVER=org.postgresql.Driver
      - ALPINE_DATABASE_USERNAME=dependencytrack
      - ALPINE_DATABASE_PASSWORD=dependencytrack
    volumes:
      - dependency_track_data:/data
    networks:
      - vuln_network
    depends_on:
      - postgres-dt

  dependency-track-frontend:
    image: dependencytrack/frontend:latest
    container_name: vuln-dependency-track-frontend
    ports:
      - "8082:8080"
    environment:
      - API_BASE_URL=http://dependency-track:8080
    networks:
      - vuln_network
    depends_on:
      - dependency-track

  # PostgreSQL para Dependency-Track
  postgres-dt:
    image: postgres:15
    container_name: vuln-postgres-dt
    environment:
      - POSTGRES_USER=dependencytrack
      - POSTGRES_PASSWORD=dependencytrack
      - POSTGRES_DB=dependencytrack
    volumes:
      - postgres_dt_data:/var/lib/postgresql/data
    networks:
      - vuln_network

  # Grafana para dashboards
  grafana:
    image: grafana/grafana:10.2.0
    container_name: vuln-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      - vuln_network

  # Prometheus para m√©tricas
  prometheus:
    image: prom/prometheus:latest
    container_name: vuln-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - vuln_network

volumes:
  sonarqube_data:
  sonarqube_logs:
  sonarqube_extensions:
  postgres_data:
  postgres_dd_data:
  postgres_dt_data:
  zap_data:
  trivy_cache:
  defectdojo_media:
  dependency_track_data:
  grafana_data:
  prometheus_data:

networks:
  vuln_network:
    driver: bridge
```

### 2. Configuraci√≥n de Prometheus para M√©tricas

```yaml
# prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "vulnerability_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'sonarqube'
    static_configs:
      - targets: ['sonarqube:9000']
    metrics_path: '/api/monitoring/metrics'
    basic_auth:
      username: 'admin'
      password: 'admin'

  - job_name: 'dependency-track'
    static_configs:
      - targets: ['dependency-track:8080']
    metrics_path: '/api/metrics'
    bearer_token: 'your-api-key'

  - job_name: 'defectdojo'
    static_configs:
      - targets: ['defectdojo:8000']
    metrics_path: '/metrics'

  - job_name: 'custom-vulnerability-metrics'
    static_configs:
      - targets: ['vulnerability-exporter:8080']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

---

## üîç Implementaci√≥n SAST con SonarQube

### 1. Pipeline de An√°lisis SAST

```yaml
# .github/workflows/sast-analysis.yml
name: SAST Analysis with SonarQube

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

jobs:
  sast-analysis:
    name: SAST Security Analysis
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Shallow clones should be disabled for better analysis

    - name: Set up JDK 17
      uses: actions/setup-java@v3
      with:
        java-version: '17'
        distribution: 'temurin'

    - name: Cache SonarQube packages
      uses: actions/cache@v3
      with:
        path: ~/.sonar/cache
        key: ${{ runner.os }}-sonar
        restore-keys: ${{ runner.os }}-sonar

    - name: Cache Maven packages
      uses: actions/cache@v3
      with:
        path: ~/.m2
        key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
        restore-keys: ${{ runner.os }}-m2

    - name: Run unit tests with coverage
      run: |
        mvn clean test jacoco:report

    - name: SonarQube Scan
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
      run: |
        mvn sonar:sonar \
          -Dsonar.projectKey=${{ github.repository_owner }}_${{ github.event.repository.name }} \
          -Dsonar.organization=${{ github.repository_owner }} \
          -Dsonar.host.url=https://sonarcloud.io \
          -Dsonar.login=${{ secrets.SONAR_TOKEN }} \
          -Dsonar.coverage.jacoco.xmlReportPaths=target/site/jacoco/jacoco.xml \
          -Dsonar.pullrequest.key=${{ github.event.pull_request.number }} \
          -Dsonar.pullrequest.branch=${{ github.event.pull_request.head.ref }} \
          -Dsonar.pullrequest.base=${{ github.event.pull_request.base.ref }}

    - name: Wait for Quality Gate
      uses: sonarqube-quality-gate-action@master
      timeout-minutes: 5
      env:
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

    - name: Get SonarQube results
      id: sonar-results
      run: |
        # Wait for analysis to complete
        sleep 30
        
        # Get project status
        PROJECT_KEY="${{ github.repository_owner }}_${{ github.event.repository.name }}"
        QUALITY_GATE_STATUS=$(curl -s -u ${{ secrets.SONAR_TOKEN }}: \
          "https://sonarcloud.io/api/qualitygates/project_status?projectKey=${PROJECT_KEY}" \
          | jq -r '.projectStatus.status')
        
        echo "quality_gate_status=${QUALITY_GATE_STATUS}" >> $GITHUB_OUTPUT
        
        # Get issues count
        ISSUES=$(curl -s -u ${{ secrets.SONAR_TOKEN }}: \
          "https://sonarcloud.io/api/issues/search?componentKeys=${PROJECT_KEY}&severities=BLOCKER,CRITICAL,MAJOR" \
          | jq '.total')
        
        echo "issues_count=${ISSUES}" >> $GITHUB_OUTPUT

    - name: Fail on Quality Gate failure
      if: steps.sonar-results.outputs.quality_gate_status != 'OK'
      run: |
        echo "Quality Gate failed with status: ${{ steps.sonar-results.outputs.quality_gate_status }}"
        echo "Issues found: ${{ steps.sonar-results.outputs.issues_count }}"
        exit 1

    - name: Create security report
      run: |
        cat > security-report.md << EOF
        # SAST Security Analysis Report
        
        **Quality Gate Status**: ${{ steps.sonar-results.outputs.quality_gate_status }}
        **Issues Found**: ${{ steps.sonar-results.outputs.issues_count }}
        **Analysis Date**: $(date)
        **Project**: ${{ github.repository }}
        **Branch**: ${{ github.ref_name }}
        
        ## Summary
        Static Application Security Testing (SAST) analysis completed.
        
        [View detailed results on SonarCloud](https://sonarcloud.io/project/overview?id=${{ github.repository_owner }}_${{ github.event.repository.name }})
        EOF

    - name: Upload security report
      uses: actions/upload-artifact@v3
      with:
        name: sast-security-report
        path: security-report.md
```

### 2. Configuraci√≥n SonarQube Quality Profile

```xml
<!-- sonar-project.properties -->
sonar.projectKey=myproject
sonar.organization=myorg
sonar.projectName=My Project
sonar.projectVersion=1.0

# Source code settings
sonar.sources=src/main
sonar.tests=src/test
sonar.java.binaries=target/classes
sonar.java.test.binaries=target/test-classes

# Coverage settings
sonar.coverage.jacoco.xmlReportPaths=target/site/jacoco/jacoco.xml
sonar.junit.reportPaths=target/surefire-reports

# Security settings
sonar.security.hotspots.minSeverity=MEDIUM
sonar.security.review.minSeverity=MINOR

# Quality gate settings
sonar.qualitygate.wait=true
sonar.qualitygate.timeout=300

# Exclusions
sonar.exclusions=**/target/**,**/node_modules/**,**/*.min.js
sonar.test.exclusions=**/target/**

# Language specific settings
sonar.java.source=11
sonar.java.target=11
sonar.javascript.lcov.reportPaths=coverage/lcov.info
sonar.python.coverage.reportPaths=coverage.xml
```

---

## üê≥ Container Scanning con Trivy

### 1. Integraci√≥n de Trivy en CI/CD

```yaml
# .github/workflows/container-security.yml
name: Container Security Scanning

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  container-scan:
    name: Container Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Build Docker image
      run: |
        docker build -t ${{ github.repository }}:${{ github.sha }} .

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: '${{ github.repository }}:${{ github.sha }}'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

    - name: Run Trivy with custom policies
      run: |
        # Install Trivy CLI
        sudo apt-get update
        sudo apt-get install wget apt-transport-https gnupg lsb-release
        wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
        echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
        sudo apt-get update
        sudo apt-get install trivy

        # Create custom policy
        mkdir -p policies
        cat > policies/security-policy.rego << 'EOF'
        package trivy
        
        import future.keywords.contains
        import future.keywords.if
        import future.keywords.in
        
        # Deny critical and high severity vulnerabilities
        deny[res] {
            input.Results[_].Vulnerabilities[i].Severity == "CRITICAL"
            res := sprintf("Critical vulnerability found: %s", [input.Results[_].Vulnerabilities[i].VulnerabilityID])
        }
        
        deny[res] {
            input.Results[_].Vulnerabilities[i].Severity == "HIGH"
            input.Results[_].Vulnerabilities[i].FixedVersion != ""
            res := sprintf("High severity vulnerability with available fix: %s", [input.Results[_].Vulnerabilities[i].VulnerabilityID])
        }
        
        # Deny specific vulnerable packages
        vulnerable_packages := [
            "log4j-core",
            "spring-core",
            "jackson-databind"
        ]
        
        deny[res] {
            input.Results[_].Vulnerabilities[i].PkgName in vulnerable_packages
            input.Results[_].Vulnerabilities[i].Severity in ["HIGH", "CRITICAL"]
            res := sprintf("Vulnerable package detected: %s with severity %s", [
                input.Results[_].Vulnerabilities[i].PkgName,
                input.Results[_].Vulnerabilities[i].Severity
            ])
        }
        EOF

        # Scan with custom policy
        trivy image --policy policies --format json --output trivy-policy-results.json ${{ github.repository }}:${{ github.sha }}

    - name: Generate detailed security report
      run: |
        # Install yq for YAML processing
        sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
        sudo chmod +x /usr/local/bin/yq

        # Create comprehensive report
        python3 << 'EOF'
        import json
        import sys
        from datetime import datetime

        # Load Trivy results
        try:
            with open('trivy-policy-results.json', 'r') as f:
                results = json.load(f)
        except FileNotFoundError:
            print("No results file found")
            sys.exit(0)

        # Generate report
        report = {
            "scan_date": datetime.now().isoformat(),
            "image": "${{ github.repository }}:${{ github.sha }}",
            "summary": {
                "total_vulnerabilities": 0,
                "critical": 0,
                "high": 0,
                "medium": 0,
                "low": 0,
                "unknown": 0
            },
            "vulnerabilities": [],
            "recommendations": []
        }

        # Process results
        if "Results" in results:
            for result in results["Results"]:
                if "Vulnerabilities" in result:
                    for vuln in result["Vulnerabilities"]:
                        report["summary"]["total_vulnerabilities"] += 1
                        severity = vuln.get("Severity", "UNKNOWN").lower()
                        if severity in report["summary"]:
                            report["summary"][severity] += 1
                        
                        # Add to vulnerabilities list
                        report["vulnerabilities"].append({
                            "id": vuln.get("VulnerabilityID", ""),
                            "severity": vuln.get("Severity", ""),
                            "package": vuln.get("PkgName", ""),
                            "version": vuln.get("InstalledVersion", ""),
                            "fixed_version": vuln.get("FixedVersion", ""),
                            "title": vuln.get("Title", ""),
                            "description": vuln.get("Description", "")[:200] + "..." if len(vuln.get("Description", "")) > 200 else vuln.get("Description", "")
                        })

        # Generate recommendations
        if report["summary"]["critical"] > 0:
            report["recommendations"].append("üö® CRITICAL: Address critical vulnerabilities immediately")
        if report["summary"]["high"] > 0:
            report["recommendations"].append("‚ö†Ô∏è HIGH: Plan remediation for high severity vulnerabilities")
        if report["summary"]["total_vulnerabilities"] == 0:
            report["recommendations"].append("‚úÖ GOOD: No vulnerabilities detected")

        # Save report
        with open('container-security-report.json', 'w') as f:
            json.dump(report, f, indent=2)

        # Create markdown summary
        with open('container-security-summary.md', 'w') as f:
            f.write(f"""# Container Security Scan Report

        **Image**: `${{ github.repository }}:${{ github.sha }}`
        **Scan Date**: {report['scan_date']}

        ## Summary
        - **Total Vulnerabilities**: {report['summary']['total_vulnerabilities']}
        - **Critical**: {report['summary']['critical']}
        - **High**: {report['summary']['high']}
        - **Medium**: {report['summary']['medium']}
        - **Low**: {report['summary']['low']}

        ## Recommendations
        """)
            
            for rec in report["recommendations"]:
                f.write(f"- {rec}\n")
            
            if report["summary"]["critical"] > 0 or report["summary"]["high"] > 0:
                f.write(f"\n## Action Required\n")
                f.write(f"This image contains {report['summary']['critical']} critical and {report['summary']['high']} high severity vulnerabilities.\n")
                f.write(f"Please review and address these issues before deployment.\n")

        print(f"Scan completed. Found {report['summary']['total_vulnerabilities']} vulnerabilities.")
        
        # Fail build if critical vulnerabilities found
        if report['summary']['critical'] > 0:
            print("‚ùå Build failed due to critical vulnerabilities")
            sys.exit(1)
        elif report['summary']['high'] > 5:  # Allow up to 5 high severity
            print("‚ùå Build failed due to too many high severity vulnerabilities")
            sys.exit(1)
        EOF

    - name: Upload security artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: container-security-reports
        path: |
          trivy-results.sarif
          trivy-policy-results.json
          container-security-report.json
          container-security-summary.md

    - name: Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          
          try {
            const summary = fs.readFileSync('container-security-summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Container Security Scan Results\n\n${summary}`
            });
          } catch (error) {
            console.log('Could not read summary file:', error);
          }
```

---

## üì¶ Software Composition Analysis (SCA)

### 1. Dependency-Track Integration

```python
#!/usr/bin/env python3
# tools/dependency_track_integration.py

import requests
import json
import base64
import time
import sys
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class Vulnerability:
    uuid: str
    source: str
    vuln_id: str
    title: str
    description: str
    severity: str
    cvss_score: float
    component_name: str
    component_version: str
    recommendation: str

class DependencyTrackClient:
    def __init__(self, base_url: str, api_key: str):
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.session = requests.Session()
        self.session.headers.update({
            'X-API-Key': api_key,
            'Content-Type': 'application/json'
        })
    
    def create_project(self, name: str, version: str, description: str = "") -> Dict:
        """Crear un nuevo proyecto en Dependency-Track"""
        data = {
            "name": name,
            "version": version,
            "description": description,
            "classifier": "APPLICATION",
            "active": True
        }
        
        response = self.session.put(f"{self.base_url}/api/v1/project", json=data)
        response.raise_for_status()
        return response.json()
    
    def upload_bom(self, project_uuid: str, bom_content: str, auto_create: bool = True) -> str:
        """Subir BOM (Bill of Materials) al proyecto"""
        # Codificar BOM in base64
        bom_b64 = base64.b64encode(bom_content.encode()).decode()
        
        data = {
            "project": project_uuid,
            "bom": bom_b64,
            "autoCreate": auto_create
        }
        
        response = self.session.put(f"{self.base_url}/api/v1/bom", json=data)
        response.raise_for_status()
        
        # Obtener token de procesamiento
        return response.json().get("token")
    
    def check_bom_processing(self, token: str) -> Dict:
        """Verificar el estado del procesamiento del BOM"""
        response = self.session.get(f"{self.base_url}/api/v1/bom/token/{token}")
        response.raise_for_status()
        return response.json()
    
    def wait_for_bom_processing(self, token: str, timeout: int = 300) -> bool:
        """Esperar a que el BOM sea procesado"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            status = self.check_bom_processing(token)
            if status.get("processing", True) == False:
                return True
            time.sleep(10)
        
        return False
    
    def get_project_vulnerabilities(self, project_uuid: str) -> List[Vulnerability]:
        """Obtener vulnerabilidades del proyecto"""
        response = self.session.get(f"{self.base_url}/api/v1/vulnerability/project/{project_uuid}")
        response.raise_for_status()
        
        vulnerabilities = []
        for vuln_data in response.json():
            vuln = Vulnerability(
                uuid=vuln_data.get("uuid", ""),
                source=vuln_data.get("source", ""),
                vuln_id=vuln_data.get("vulnId", ""),
                title=vuln_data.get("title", ""),
                description=vuln_data.get("description", ""),
                severity=vuln_data.get("severity", ""),
                cvss_score=vuln_data.get("cvssV3BaseScore", 0.0),
                component_name=vuln_data.get("component", {}).get("name", ""),
                component_version=vuln_data.get("component", {}).get("version", ""),
                recommendation=vuln_data.get("recommendation", "")
            )
            vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def get_project_metrics(self, project_uuid: str) -> Dict:
        """Obtener m√©tricas del proyecto"""
        response = self.session.get(f"{self.base_url}/api/v1/metrics/project/{project_uuid}/current")
        response.raise_for_status()
        return response.json()
    
    def create_finding(self, component_uuid: str, vulnerability_uuid: str, analysis_state: str = "NOT_SET") -> Dict:
        """Crear un finding para una vulnerabilidad"""
        data = {
            "component": component_uuid,
            "vulnerability": vulnerability_uuid,
            "analysisState": analysis_state,
            "isSuppressed": False
        }
        
        response = self.session.put(f"{self.base_url}/api/v1/analysis", json=data)
        response.raise_for_status()
        return response.json()

class SCAScanner:
    def __init__(self, dt_client: DependencyTrackClient):
        self.dt_client = dt_client
    
    def generate_cyclonedx_bom(self, project_path: str, package_manager: str) -> str:
        """Generar BOM en formato CycloneDX"""
        if package_manager.lower() == "maven":
            return self._generate_maven_bom(project_path)
        elif package_manager.lower() == "npm":
            return self._generate_npm_bom(project_path)
        elif package_manager.lower() == "pip":
            return self._generate_python_bom(project_path)
        else:
            raise ValueError(f"Unsupported package manager: {package_manager}")
    
    def _generate_maven_bom(self, project_path: str) -> str:
        """Generar BOM para proyecto Maven"""
        import subprocess
        import os
        
        # Usar el plugin CycloneDX para Maven
        cmd = [
            "mvn",
            "org.cyclonedx:cyclonedx-maven-plugin:makeAggregateBom",
            "-DoutputFormat=json",
            "-DoutputName=bom"
        ]
        
        result = subprocess.run(cmd, cwd=project_path, capture_output=True, text=True)
        if result.returncode != 0:
            raise Exception(f"Failed to generate Maven BOM: {result.stderr}")
        
        bom_path = os.path.join(project_path, "target", "bom.json")
        with open(bom_path, 'r') as f:
            return f.read()
    
    def _generate_npm_bom(self, project_path: str) -> str:
        """Generar BOM para proyecto NPM"""
        import subprocess
        import os
        
        # Instalar y usar @cyclonedx/bom
        cmd = ["npx", "@cyclonedx/bom", "--output", "bom.json"]
        
        result = subprocess.run(cmd, cwd=project_path, capture_output=True, text=True)
        if result.returncode != 0:
            raise Exception(f"Failed to generate NPM BOM: {result.stderr}")
        
        bom_path = os.path.join(project_path, "bom.json")
        with open(bom_path, 'r') as f:
            return f.read()
    
    def _generate_python_bom(self, project_path: str) -> str:
        """Generar BOM para proyecto Python"""
        import subprocess
        import os
        
        # Usar cyclonedx-bom
        cmd = ["cyclonedx-bom", "-o", "bom.json", project_path]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            raise Exception(f"Failed to generate Python BOM: {result.stderr}")
        
        with open("bom.json", 'r') as f:
            return f.read()
    
    def scan_project(self, project_name: str, project_version: str, project_path: str, package_manager: str) -> Dict:
        """Escanear proyecto completo"""
        print(f"Starting SCA scan for {project_name} v{project_version}")
        
        # Crear proyecto en Dependency-Track
        project = self.dt_client.create_project(project_name, project_version)
        project_uuid = project["uuid"]
        print(f"Created project with UUID: {project_uuid}")
        
        # Generar BOM
        print("Generating BOM...")
        bom_content = self.generate_cyclonedx_bom(project_path, package_manager)
        
        # Subir BOM
        print("Uploading BOM...")
        token = self.dt_client.upload_bom(project_uuid, bom_content)
        
        # Esperar procesamiento
        print("Waiting for BOM processing...")
        if not self.dt_client.wait_for_bom_processing(token):
            raise Exception("BOM processing timeout")
        
        # Obtener vulnerabilidades
        print("Retrieving vulnerabilities...")
        vulnerabilities = self.dt_client.get_project_vulnerabilities(project_uuid)
        
        # Obtener m√©tricas
        metrics = self.dt_client.get_project_metrics(project_uuid)
        
        return {
            "project_uuid": project_uuid,
            "vulnerabilities": vulnerabilities,
            "metrics": metrics,
            "scan_date": datetime.now().isoformat()
        }
    
    def generate_report(self, scan_results: Dict) -> Dict:
        """Generar reporte de SCA"""
        vulnerabilities = scan_results["vulnerabilities"]
        metrics = scan_results["metrics"]
        
        # Clasificar vulnerabilidades por severidad
        severity_counts = {
            "CRITICAL": 0,
            "HIGH": 0,
            "MEDIUM": 0,
            "LOW": 0,
            "UNASSIGNED": 0
        }
        
        high_risk_components = []
        
        for vuln in vulnerabilities:
            severity = vuln.severity.upper()
            if severity in severity_counts:
                severity_counts[severity] += 1
            
            # Identificar componentes de alto riesgo
            if severity in ["CRITICAL", "HIGH"] and vuln.cvss_score >= 7.0:
                high_risk_components.append({
                    "component": f"{vuln.component_name}:{vuln.component_version}",
                    "vulnerability": vuln.vuln_id,
                    "severity": vuln.severity,
                    "cvss_score": vuln.cvss_score,
                    "description": vuln.title
                })
        
        report = {
            "project_uuid": scan_results["project_uuid"],
            "scan_date": scan_results["scan_date"],
            "summary": {
                "total_vulnerabilities": len(vulnerabilities),
                "total_components": metrics.get("components", 0),
                "vulnerable_components": metrics.get("vulnerableComponents", 0),
                "severity_distribution": severity_counts,
                "risk_score": self._calculate_risk_score(severity_counts)
            },
            "high_risk_components": high_risk_components,
            "recommendations": self._generate_recommendations(severity_counts, high_risk_components)
        }
        
        return report
    
    def _calculate_risk_score(self, severity_counts: Dict) -> float:
        """Calcular score de riesgo basado en severidades"""
        weights = {
            "CRITICAL": 10.0,
            "HIGH": 7.5,
            "MEDIUM": 4.0,
            "LOW": 1.0,
            "UNASSIGNED": 0.5
        }
        
        total_score = sum(count * weights.get(severity, 0) for severity, count in severity_counts.items())
        total_vulns = sum(severity_counts.values())
        
        if total_vulns == 0:
            return 0.0
        
        return min(total_score / total_vulns, 10.0)
    
    def _generate_recommendations(self, severity_counts: Dict, high_risk_components: List[Dict]) -> List[str]:
        """Generar recomendaciones basadas en resultados"""
        recommendations = []
        
        if severity_counts["CRITICAL"] > 0:
            recommendations.append(f"üö® URGENT: Address {severity_counts['CRITICAL']} critical vulnerabilities immediately")
        
        if severity_counts["HIGH"] > 0:
            recommendations.append(f"‚ö†Ô∏è HIGH PRIORITY: Plan remediation for {severity_counts['HIGH']} high severity vulnerabilities")
        
        if len(high_risk_components) > 0:
            recommendations.append(f"üîç REVIEW: {len(high_risk_components)} components have high-risk vulnerabilities")
        
        if severity_counts["MEDIUM"] > 10:
            recommendations.append(f"üìã MODERATE: Consider addressing {severity_counts['MEDIUM']} medium severity vulnerabilities")
        
        if sum(severity_counts.values()) == 0:
            recommendations.append("‚úÖ EXCELLENT: No known vulnerabilities detected in dependencies")
        
        return recommendations

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Software Composition Analysis with Dependency-Track')
    parser.add_argument('--dt-url', required=True, help='Dependency-Track URL')
    parser.add_argument('--dt-api-key', required=True, help='Dependency-Track API key')
    parser.add_argument('--project-name', required=True, help='Project name')
    parser.add_argument('--project-version', required=True, help='Project version')
    parser.add_argument('--project-path', required=True, help='Project path')
    parser.add_argument('--package-manager', required=True, choices=['maven', 'npm', 'pip'], help='Package manager')
    parser.add_argument('--output', help='Output file for report')
    
    args = parser.parse_args()
    
    try:
        # Inicializar cliente
        dt_client = DependencyTrackClient(args.dt_url, args.dt_api_key)
        scanner = SCAScanner(dt_client)
        
        # Escanear proyecto
        scan_results = scanner.scan_project(
            args.project_name,
            args.project_version,
            args.project_path,
            args.package_manager
        )
        
        # Generar reporte
        report = scanner.generate_report(scan_results)
        
        # Guardar reporte
        if args.output:
            with open(args.output, 'w') as f:
                json.dump(report, f, indent=2, default=str)
        else:
            print(json.dumps(report, indent=2, default=str))
        
        # Mostrar resumen
        print(f"\n=== SCA Scan Summary ===")
        print(f"Project: {args.project_name} v{args.project_version}")
        print(f"Total vulnerabilities: {report['summary']['total_vulnerabilities']}")
        print(f"Risk score: {report['summary']['risk_score']:.1f}/10")
        
        for rec in report['recommendations']:
            print(f"- {rec}")
        
        # Exit code basado en severidad
        if report['summary']['severity_distribution']['CRITICAL'] > 0:
            sys.exit(2)  # Critical vulnerabilities
        elif report['summary']['severity_distribution']['HIGH'] > 0:
            sys.exit(1)  # High vulnerabilities
        else:
            sys.exit(0)  # No critical/high vulnerabilities
        
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(3)

if __name__ == "__main__":
    main()
```

---

## üîÑ DAST con OWASP ZAP

### 1. Pipeline de DAST Automatizado

```yaml
# .github/workflows/dast-security.yml
name: DAST Security Testing

on:
  schedule:
    - cron: '0 3 * * *'  # Daily at 3 AM
  workflow_dispatch:
    inputs:
      target_url:
        description: 'Target URL to scan'
        required: true
        default: 'http://localhost:8080'
      scan_type:
        description: 'Scan type'
        required: true
        default: 'baseline'
        type: choice
        options:
        - baseline
        - full
        - api

jobs:
  dast-scan:
    name: DAST Security Scan
    runs-on: ubuntu-latest
    
    services:
      app:
        image: ${{ github.repository }}:latest
        ports:
          - 8080:8080
        env:
          SPRING_PROFILES_ACTIVE: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Wait for application to start
      run: |
        timeout 60s bash -c 'until curl -f http://localhost:8080/health; do sleep 2; done'

    - name: Create ZAP configuration
      run: |
        mkdir -p zap-config
        
        # Create ZAP baseline configuration
        cat > zap-config/baseline.conf << 'EOF'
        # ZAP Baseline Configuration
        
        # Authentication
        -config auth.method=form
        -config auth.loginurl=http://localhost:8080/login
        -config auth.username=test@example.com
        -config auth.password=testpassword
        
        # Session management
        -config session.sessiontokens=JSESSIONID,sessionid
        
        # Scanning rules
        -config scanner.strength=MEDIUM
        -config scanner.alertthreshold=MEDIUM
        
        # Reports
        -config report.format=json,html,xml
        EOF
        
        # Create API scan configuration
        cat > zap-config/api.conf << 'EOF'
        # ZAP API Scan Configuration
        
        # API specification
        -config api.spec=http://localhost:8080/v3/api-docs
        -config api.format=openapi
        
        # API authentication
        -config api.auth.header=Authorization
        -config api.auth.value=Bearer ${{ secrets.API_TOKEN }}
        
        # API scanning
        -config api.scan.depth=5
        -config api.scan.coverage=100
        EOF

    - name: Run ZAP Baseline Scan
      if: github.event.inputs.scan_type == 'baseline' || github.event.inputs.scan_type == ''
      run: |
        docker run --network host \
          -v $(pwd)/zap-config:/zap/wrk/config \
          -v $(pwd)/zap-reports:/zap/wrk/reports \
          zaproxy/zap-stable:latest \
          zap-baseline.py \
          -t http://localhost:8080 \
          -g gen.conf \
          -r baseline-report.html \
          -J baseline-report.json \
          -x baseline-report.xml \
          -c zap-config/baseline.conf

    - name: Run ZAP Full Scan
      if: github.event.inputs.scan_type == 'full'
      run: |
        docker run --network host \
          -v $(pwd)/zap-config:/zap/wrk/config \
          -v $(pwd)/zap-reports:/zap/wrk/reports \
          zaproxy/zap-stable:latest \
          zap-full-scan.py \
          -t http://localhost:8080 \
          -g gen.conf \
          -r full-report.html \
          -J full-report.json \
          -x full-report.xml \
          -T 60

    - name: Run ZAP API Scan
      if: github.event.inputs.scan_type == 'api'
      run: |
        docker run --network host \
          -v $(pwd)/zap-config:/zap/wrk/config \
          -v $(pwd)/zap-reports:/zap/wrk/reports \
          zaproxy/zap-stable:latest \
          zap-api-scan.py \
          -t http://localhost:8080/v3/api-docs \
          -f openapi \
          -g gen.conf \
          -r api-report.html \
          -J api-report.json \
          -x api-report.xml

    - name: Process ZAP Results
      run: |
        # Install jq for JSON processing
        sudo apt-get update && sudo apt-get install -y jq
        
        # Process results based on scan type
        SCAN_TYPE="${{ github.event.inputs.scan_type }}"
        if [ -z "$SCAN_TYPE" ]; then
          SCAN_TYPE="baseline"
        fi
        
        REPORT_FILE="zap-reports/${SCAN_TYPE}-report.json"
        
        if [ -f "$REPORT_FILE" ]; then
          # Extract key metrics
          HIGH_ALERTS=$(jq '[.site[].alerts[] | select(.riskdesc | startswith("High"))] | length' "$REPORT_FILE")
          MEDIUM_ALERTS=$(jq '[.site[].alerts[] | select(.riskdesc | startswith("Medium"))] | length' "$REPORT_FILE")
          LOW_ALERTS=$(jq '[.site[].alerts[] | select(.riskdesc | startswith("Low"))] | length' "$REPORT_FILE")
          INFO_ALERTS=$(jq '[.site[].alerts[] | select(.riskdesc | startswith("Informational"))] | length' "$REPORT_FILE")
          
          echo "HIGH_ALERTS=$HIGH_ALERTS" >> $GITHUB_ENV
          echo "MEDIUM_ALERTS=$MEDIUM_ALERTS" >> $GITHUB_ENV
          echo "LOW_ALERTS=$LOW_ALERTS" >> $GITHUB_ENV
          echo "INFO_ALERTS=$INFO_ALERTS" >> $GITHUB_ENV
          
          # Create summary report
          cat > dast-summary.md << EOF
        # DAST Security Scan Report
        
        **Scan Type**: ${SCAN_TYPE}
        **Target**: http://localhost:8080
        **Scan Date**: $(date)
        
        ## Summary
        - **High Risk**: $HIGH_ALERTS
        - **Medium Risk**: $MEDIUM_ALERTS
        - **Low Risk**: $LOW_ALERTS
        - **Informational**: $INFO_ALERTS
        
        ## Risk Assessment
        EOF
          
          if [ "$HIGH_ALERTS" -gt 0 ]; then
            echo "üö® **CRITICAL**: $HIGH_ALERTS high-risk vulnerabilities detected. Immediate action required." >> dast-summary.md
          elif [ "$MEDIUM_ALERTS" -gt 5 ]; then
            echo "‚ö†Ô∏è **WARNING**: $MEDIUM_ALERTS medium-risk vulnerabilities detected. Review recommended." >> dast-summary.md
          else
            echo "‚úÖ **GOOD**: No critical security issues detected." >> dast-summary.md
          fi
          
          # Extract top vulnerabilities
          echo "" >> dast-summary.md
          echo "## Top Vulnerabilities" >> dast-summary.md
          jq -r '.site[].alerts[] | select(.riskdesc | startswith("High")) | "- **\(.name)**: \(.desc | gsub("\n"; " ") | .[0:100])..."' "$REPORT_FILE" | head -5 >> dast-summary.md
        else
          echo "No ZAP report found"
          exit 1
        fi

    - name: Upload ZAP Reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: zap-reports
        path: |
          zap-reports/
          dast-summary.md

    - name: Create Issue for High Vulnerabilities
      if: env.HIGH_ALERTS > 0
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('dast-summary.md', 'utf8');
          
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `üö® DAST Security Alert: ${process.env.HIGH_ALERTS} High-Risk Vulnerabilities Detected`,
            body: summary,
            labels: ['security', 'vulnerability', 'high-priority']
          });

    - name: Fail on High Risk Vulnerabilities
      if: env.HIGH_ALERTS > 0
      run: |
        echo "‚ùå Build failed due to $HIGH_ALERTS high-risk vulnerabilities"
        exit 1

    - name: Send Slack Notification
      if: always()
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        custom_payload: |
          {
            attachments: [{
              color: '${{ env.HIGH_ALERTS > 0 && 'danger' || env.MEDIUM_ALERTS > 5 && 'warning' || 'good' }}',
              blocks: [{
                type: 'section',
                text: {
                  type: 'mrkdwn',
                  text: `*DAST Security Scan Results*\n*Repository:* ${process.env.GITHUB_REPOSITORY}\n*High Risk:* ${process.env.HIGH_ALERTS}\n*Medium Risk:* ${process.env.MEDIUM_ALERTS}\n*Status:* ${{ job.status }}`
                }
              }]
            }]
          }
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

---

## üìä Vulnerability Management Dashboard

### 1. Grafana Dashboard para Vulnerabilidades

```json
{
  "dashboard": {
    "id": null,
    "title": "Vulnerability Management Dashboard",
    "tags": ["security", "vulnerability", "scanning"],
    "timezone": "browser",
    "refresh": "5m",
    "panels": [
      {
        "id": 1,
        "title": "Vulnerability Overview",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(vulnerability_total)",
            "legendFormat": "Total Vulnerabilities"
          },
          {
            "expr": "sum(vulnerability_total{severity=\"critical\"})",
            "legendFormat": "Critical"
          },
          {
            "expr": "sum(vulnerability_total{severity=\"high\"})",
            "legendFormat": "High"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "palette-classic"
            },
            "unit": "short"
          }
        }
      },
      {
        "id": 2,
        "title": "Vulnerabilities by Severity",
        "type": "piechart",
        "targets": [
          {
            "expr": "sum by (severity) (vulnerability_total)",
            "legendFormat": "{{severity}}"
          }
        ]
      },
      {
        "id": 3,
        "title": "Vulnerability Trends",
        "type": "timeseries",
        "targets": [
          {
            "expr": "sum(vulnerability_total{severity=\"critical\"})",
            "legendFormat": "Critical"
          },
          {
            "expr": "sum(vulnerability_total{severity=\"high\"})",
            "legendFormat": "High"
          },
          {
            "expr": "sum(vulnerability_total{severity=\"medium\"})",
            "legendFormat": "Medium"
          }
        ]
      },
      {
        "id": 4,
        "title": "Scan Success Rate",
        "type": "gauge",
        "targets": [
          {
            "expr": "rate(vulnerability_scan_success_total[1h]) / rate(vulnerability_scan_total[1h]) * 100",
            "legendFormat": "Success Rate"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "yellow", "value": 80},
                {"color": "green", "value": 95}
              ]
            }
          }
        }
      },
      {
        "id": 5,
        "title": "Top Vulnerable Components",
        "type": "table",
        "targets": [
          {
            "expr": "topk(10, sum by (component, version) (vulnerability_total{severity=~\"critical|high\"}))",
            "format": "table",
            "instant": true
          }
        ]
      },
      {
        "id": 6,
        "title": "Remediation Time",
        "type": "histogram",
        "targets": [
          {
            "expr": "histogram_quantile(0.5, vulnerability_remediation_time_bucket)",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.95, vulnerability_remediation_time_bucket)",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "id": 7,
        "title": "Scans by Type",
        "type": "bargauge",
        "targets": [
          {
            "expr": "sum by (scan_type) (rate(vulnerability_scan_total[1h]))",
            "legendFormat": "{{scan_type}}"
          }
        ]
      },
      {
        "id": 8,
        "title": "False Positive Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(vulnerability_false_positive_total) / sum(vulnerability_total) * 100",
            "legendFormat": "False Positive Rate"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": 0},
                {"color": "yellow", "value": 10},
                {"color": "red", "value": 25}
              ]
            }
          }
        }
      }
    ],
    "time": {
      "from": "now-7d",
      "to": "now"
    }
  }
}
```

---

## üìã Ejercicios Pr√°cticos

### Ejercicio 1: Implementar SAST con SonarQube

**Objetivo**: Configurar an√°lisis SAST automatizado.

**Tareas**:

1. Configurar SonarQube server
2. Crear quality gates personalizados
3. Integrar con pipeline CI/CD
4. Configurar reportes automatizados

### Ejercicio 2: Container Scanning con Trivy

**Objetivo**: Implementar scanning de contenedores.

**Componentes**:

- Trivy integration en CI/CD
- Pol√≠ticas de seguridad personalizadas
- Reportes automatizados
- Bloqueo de deployments inseguros

### Ejercicio 3: SCA con Dependency-Track

**Objetivo**: An√°lisis de composici√≥n de software.

**Tareas**:

- Configurar Dependency-Track
- Generar y subir BOMs
- Monitorear vulnerabilidades
- Crear reportes de dependencias

---

## üß™ Laboratorio

### Lab 1: Stack Completo de Vulnerability Scanning

1. **Desplegar infraestructura**:

   ```bash
   docker-compose -f docker-compose.vulnerability-scanning.yml up -d
   ```

2. **Configurar scanners**:
   - SonarQube para SAST
   - ZAP para DAST
   - Trivy para containers
   - Dependency-Track para SCA

3. **Configurar pipelines**:
   - GitHub Actions workflows
   - Pol√≠ticas de seguridad
   - Reportes automatizados

### Lab 2: Vulnerability Management

1. **Implementar DefectDojo**
2. **Configurar workflows de remediaci√≥n**
3. **Crear dashboards de m√©tricas**
4. **Automatizar reportes**

---

## üìñ Best Practices

### 1. Principios de Vulnerability Scanning

```yaml
scanning_principles:
  shift_left:
    - "Escanear temprano en el ciclo de desarrollo"
    - "Integrar en IDEs y herramientas de desarrollo"
    - "Feedback r√°pido a desarrolladores"
  
  automation:
    - "Automatizar todos los tipos de scanning"
    - "Integrar en pipelines CI/CD"
    - "Escaneo continuo de producci√≥n"
  
  prioritization:
    - "Priorizar por riesgo e impacto de negocio"
    - "Considerar contexto de la aplicaci√≥n"
    - "Enfocarse en vulnerabilidades explotables"
```

### 2. Gesti√≥n de Falsos Positivos

```yaml
false_positive_management:
  identification:
    - "An√°lisis manual de vulnerabilidades reportadas"
    - "Validaci√≥n en contexto de aplicaci√≥n"
    - "Pruebas de explotabilidad"
  
  suppression:
    - "Documentar razones para supresi√≥n"
    - "Revisi√≥n peri√≥dica de supresiones"
    - "Aprobaci√≥n de m√∫ltiples personas"
  
  continuous_improvement:
    - "Entrenar herramientas con feedback"
    - "Ajustar configuraciones de scanning"
    - "M√©tricas de precisi√≥n de herramientas"
```

---

## ‚úÖ Resumen del M√≥dulo

En este m√≥dulo has aprendido:

1. **Arquitectura de vulnerability scanning** - Stack completo de herramientas
2. **SAST con SonarQube** - An√°lisis est√°tico de c√≥digo
3. **Container scanning con Trivy** - Seguridad de contenedores
4. **SCA con Dependency-Track** - An√°lisis de dependencias
5. **DAST con OWASP ZAP** - Testing din√°mico de aplicaciones
6. **Vulnerability management** - Gesti√≥n integral de vulnerabilidades
7. **Dashboards y m√©tricas** - Monitoreo y reportes
8. **Best practices** - Principios de scanning efectivo

### Pr√≥ximos pasos

- **M√≥dulo 10**: Distributed tracing con Jaeger
- **M√≥dulo 11**: Application Performance Monitoring (APM)
- **M√≥dulo 12**: Health checks y circuit breakers

¬°Contin√∫a con el siguiente m√≥dulo para dominar el distributed tracing!
